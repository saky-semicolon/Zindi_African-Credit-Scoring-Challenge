{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fByw8GyLukXb",
    "outputId": "f46f916a-fee9-454f-88ae-34660b001756"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "      Successfully uninstalled scikit-learn-1.6.0\n",
      "Successfully installed scikit-learn-1.6.1\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (from imblearn) (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Installing collected packages: imblearn\n",
      "Successfully installed imblearn-0.0\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n",
      "Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: catboost\n",
      "Successfully installed catboost-1.2.7\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn\n",
    "!pip install torch\n",
    "!pip install imblearn\n",
    "!pip install catboost\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KnTouahDu93q"
   },
   "outputs": [],
   "source": [
    "#Import All Libraies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NS1tMW82u0As"
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train = pd.read_csv(\"/content/Train.csv\")\n",
    "test = pd.read_csv(\"/content/Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKEOJm2TvKb7"
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def feature_engineer(df):\n",
    "    df['days_to_repay'] = (pd.to_datetime(df['due_date']) - pd.to_datetime(df['disbursement_date'])).dt.days\n",
    "    df['repay_ratio'] = df['Total_Amount_to_Repay'] / df['Total_Amount']\n",
    "    df['amount_duration_ratio'] = df['Total_Amount'] / df['duration']\n",
    "    df['disbursement_month'] = pd.to_datetime(df['disbursement_date']).dt.month\n",
    "    df['amount_duration_interaction'] = df['Total_Amount'] * df['duration']\n",
    "    df['repay_duration_interaction'] = df['Total_Amount_to_Repay'] * df['duration']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTnsdaVZvKzZ"
   },
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "train = feature_engineer(train)\n",
    "test = feature_engineer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDJ3ZeiHvK2m"
   },
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "categorical_features = ['loan_type', 'New_versus_Repeat', 'country_id']\n",
    "for feature in categorical_features:\n",
    "    unique_labels = train[feature].unique()\n",
    "    label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    train[feature] = train[feature].map(label_mapping)\n",
    "    if feature in test.columns:\n",
    "        test[feature] = test[feature].map(label_mapping)\n",
    "        test[feature] = test[feature].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCSg5C34vXCr"
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "drop_columns = ['ID', 'customer_id', 'tbl_loan_id', 'lender_id', 'disbursement_date', 'due_date']\n",
    "X = train.drop(columns=drop_columns + ['target']).values\n",
    "y = train['target'].values\n",
    "X_test = test.drop(columns=drop_columns).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDGxfavPvXKq"
   },
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1CB__odvXOB"
   },
   "outputs": [],
   "source": [
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPANG70_vXQt"
   },
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05mlFeTavXUH"
   },
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  # Unsqueeze for binary classification\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)  # Unsqueeze for binary classification\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8scKXGrvXYn"
   },
   "outputs": [],
   "source": [
    "# Create Dataset and DataLoader\n",
    "class TabularDataset(Dataset):\n",
    "    def _init_(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def _len_(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szxEmLMUvXas"
   },
   "outputs": [],
   "source": [
    "# Define the Deep Learning Model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def _init_(self, input_size, hidden_size=128, dropout_rate=0.3):\n",
    "        super(NeuralNetwork, self)._init_()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_0vE60T2HRh"
   },
   "outputs": [],
   "source": [
    "# Create Dataset and DataLoader\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y): # Changed _init_ to __init__\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self): # Changed _len_ to __len__\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx): # Changed _getitem_ to __getitem__\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbVCW_Fx2J_O"
   },
   "outputs": [],
   "source": [
    "# Define the Deep Learning Model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, dropout_rate=0.3): # Changed _init_ to __init__\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZLefFKa2WiU"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning for Neural Network\n",
    "param_grid = {\n",
    "    'learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'hidden_size': [64, 128, 256],\n",
    "    'dropout': [0.2, 0.3, 0.4]\n",
    "}\n",
    "\n",
    "best_val_f1 = 0\n",
    "best_params = { # Initialize best_params with default values\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'hidden_size': 128,\n",
    "    'dropout_rate': 0.3\n",
    "} # If no better parameters are found, these will be used.\n",
    "\n",
    "# ... (rest of your hyperparameter tuning loop) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psTd9igTwUJq"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PA43i3CQ2e2e",
    "outputId": "07d9a7b5-8721-4ae0-e7b3-3998c48b30ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 391.6519\n",
      "Epoch 2/30, Train Loss: 272.8129\n",
      "Epoch 3/30, Train Loss: 243.6655\n",
      "Epoch 4/30, Train Loss: 223.9760\n",
      "Epoch 5/30, Train Loss: 209.5504\n",
      "Epoch 6/30, Train Loss: 209.6576\n",
      "Epoch 7/30, Train Loss: 196.4218\n",
      "Epoch 8/30, Train Loss: 190.3457\n",
      "Epoch 9/30, Train Loss: 189.1491\n",
      "Epoch 10/30, Train Loss: 183.4062\n",
      "Epoch 11/30, Train Loss: 182.2052\n",
      "Epoch 12/30, Train Loss: 178.3649\n",
      "Epoch 13/30, Train Loss: 176.8630\n",
      "Epoch 14/30, Train Loss: 174.4975\n",
      "Epoch 15/30, Train Loss: 174.4604\n",
      "Epoch 16/30, Train Loss: 175.3951\n",
      "Epoch 17/30, Train Loss: 171.9294\n",
      "Epoch 18/30, Train Loss: 167.3223\n",
      "Epoch 19/30, Train Loss: 175.5854\n",
      "Epoch 20/30, Train Loss: 168.1309\n",
      "Epoch 21/30, Train Loss: 168.5030\n",
      "Epoch 22/30, Train Loss: 165.6304\n",
      "Epoch 23/30, Train Loss: 176.7736\n",
      "Epoch 24/30, Train Loss: 162.9377\n",
      "Epoch 25/30, Train Loss: 165.8060\n",
      "Epoch 26/30, Train Loss: 162.2015\n",
      "Epoch 27/30, Train Loss: 167.1733\n",
      "Epoch 28/30, Train Loss: 159.6173\n",
      "Epoch 29/30, Train Loss: 159.4368\n",
      "Epoch 30/30, Train Loss: 161.4471\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'best_params' is defined from your hyperparameter tuning\n",
    "input_size = X_train.shape[1]\n",
    "model = NeuralNetwork(input_size, hidden_size=best_params['hidden_size'], dropout_rate=best_params['dropout_rate']) # Instantiate the model\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=best_params['learning_rate'])\n",
    "\n",
    "train_dataset = TabularDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "epochs = 30  # Train for more epochs with the optimal hyperparameters\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "# Now you can predict on test data:\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor).squeeze()\n",
    "    y_test_pred_binary = (y_test_pred >= 0.5).int().numpy()  # Convert to NumPy array for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1phO1KEcwMYH",
    "outputId": "a4cceae0-a138-4de7-83a2-84745fae04a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission_tuned_nn.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Predictions to Submission File\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    'target': y_test_pred_binary\n",
    "})\n",
    "submission.to_csv(\"submission_tuned_nn.csv\", index=False)\n",
    "print(\"Submission file created: submission_tuned_nn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOw6ym-WwizL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vO42RL-JwMbe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1YZHnedwMep"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2X0gMxYu97T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0R4d8z-u9-Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jX9LZlNIukai"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JU46chwJukd3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxskfPNDukgs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSRErGhgukjM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOFfeT5gukqQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcdDJkhGuktJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rd_7r2_Rukv7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZS4JpYwuk2P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZAtr6Iuuk5S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wy2qS5KFuk8Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hgz3nDPuk_D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWehxDVyulCL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fL818VO-ulHp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErMSVvZZulKn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBGAPBr8ulNq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw0VxR3sulQe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExOnfo32ulTW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BsecQPF5ulWe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aq0xot2Vulb3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
